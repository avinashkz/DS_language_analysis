facet_wrap(~academic)
survey_analysis %>%
ggplot() +
geom_bar(aes(x = dstask,fill = dstask)) +
facet_wrap(~academic)
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~dstask)
# keep
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~dstask)+theme_bw()
# keep
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~dstask)+theme_bw()+scale_fill_discrete(name = "New Legend Title")
# keep
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~dstask)+theme_bw()+scale_fill_discrete(name = "Choice of languge")
# keep
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~dstask)+theme_bw()+
scale_fill_discrete(name = "Choice of languge")+
xlab("Time of day") + ylab("Total bill") +
ggtitle("Average bill for 2 people")
# keep
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~dstask)+theme_bw()+
scale_fill_discrete(name = "Choice of languge")+
ggtitle("Task ")
xlab("Language") + ylab("Count")
# keep
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~dstask)+theme_bw()+
scale_fill_discrete(name = "Choice of languge")+
ggtitle("Task ")+xlab("Language") + ylab("Count")+
theme(plot.title = element_text(hjust = 0.5,face="bold",size=22))
# keep
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~dstask)+theme_bw()+
scale_fill_discrete(name = "Data Science task")+
ggtitle("Task ")+xlab("Choice of language") + ylab("Count")+
theme(plot.title = element_text(hjust = 0.5,face="bold",size=22))
# keep
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~dstask)+theme_bw()+
scale_fill_discrete(name = "Choice of languge")+
ggtitle("Data Science Task ")+xlab("Choice of language") + ylab("Count")+
theme(plot.title = element_text(hjust = 0.5,face="bold",size=22))
# keep
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~dstask)+theme_bw()+
scale_fill_discrete(name = "Choice of languge")+
ggtitle("Data Science Task ")+xlab("Choice of language") + ylab("Count")+
theme(plot.title = element_text(hjust = 0.5,face="bold",size=16))
# keep
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~dstask)+theme_bw()+
scale_fill_discrete(name = "Choice of languge")+
ggtitle("Data Science Task ")+xlab("Choice of language") + ylab("Count")+
theme(plot.title = element_text(hjust = 0.5,face="bold",size=16))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(stringr)
library(tidyverse)
library(knitr)
library(stringr)
kable(head(survey))
survey_analysis <- survey %>%
select(-c(1,2))
colnames(survey_analysis) <- c("academic","codingexp","lovecoding","firstprog","preferprog","dstask","noofprog")
survey_analysis %>% group_by(preferprog)%>%
summarize(count=n()) %>%
kable()
#survey_analysis$academic <- str_replace(tolower(survey_analysis$academic),c(".*econ.*",".*fin.*",".*business.*"),"Business")
#survey_analysis$academic <- str_replace(tolower(survey_analysis$academic),c(".*econ.*",".*fin.*",".*business.*"),"Business")
#?str_replace
#survey_analysis$academic <- str_replace(survey_analysis$academic,"Mathematics / Statistics","Math & Stats")
survey_analysis$academic <- str_replace(survey_analysis$academic,"Computer Science / Computer Engineering","computer")
survey_analysis$academic <- str_replace(tolower(survey_analysis$academic),".*econ.*","business")
survey_analysis$academic <- str_replace(tolower(survey_analysis$academic),".*busi.*","business")
survey_analysis$academic <- str_replace(tolower(survey_analysis$academic),".*eng.*","engineering")
# Creating a vector, putting all the fields to others
survey_clean_1 <- c("business","computer","engineering","mathematics / statistics")
#interact_clean$name[!(interact_clean$name %in% interact_clean_1)] <- "other"
survey_analysis$academic[!(survey_analysis$academic%in% survey_clean_1)] <- "other"
# Summary
survey_analysis_count<- survey_analysis %>%
group_by(academic) %>%
summarise(count=n()) %>%
View()
survey_analysis %>%
ggplot(aes(academic))+geom_bar(fill="red",position = "dodge")+
labs(title="Bar Chart",x="Academic Background",y="Count") +
theme_bw()
# not to keep this one
survey_analysis %>%
ggplot() +
geom_bar(aes(x = dstask,fill = dstask)) +
facet_wrap(~academic)
# surely not to keep
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~academic)
# keep
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~dstask)+theme_bw()+
scale_fill_discrete(name = "Choice of languge")+
ggtitle("Data Science Task ")+xlab("Choice of language") + ylab("Count")+
theme(plot.title = element_text(hjust = 0.5,face="bold",size=16))
kable(head(survey_analysis))
# keep
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~codingexp)+theme_bw()+
scale_fill_discrete(name = "Choice of languge")+
ggtitle("Data Science Task ")+xlab("Choice of language") + ylab("Count")+
theme(plot.title = element_text(hjust = 0.5,face="bold",size=16))
# keep
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~lovecoding)+theme_bw()+
scale_fill_discrete(name = "Choice of languge")+
ggtitle("Data Science Task ")+xlab("Choice of language") + ylab("Count")+
theme(plot.title = element_text(hjust = 0.5,face="bold",size=16))
survey <- read_csv("../data/survey_responses.csv")
getwd()
survey <- read_csv("../data/survey_responses.csv")
setwd("~/UBC-17/block6/554_exp/DS_language_analysis/src")
library(tidyverse)
library(knitr)
library(stringr)
survey <- read_csv("../data/survey_responses.csv")
setwd("~/UBC-17/block6/554_exp/DS_language_analysis")
survey <- read_csv("../data/survey_responses.csv")
survey <- read_csv("../data/survey_responses.csv")
survey <- read_csv("../data/survey_responses.csv")
getwd()
survey <- read_csv("../data/survey_responses.csv")
survey <- read_csv("./data/survey_responses.csv")
survey <- read_csv("../data/survey_responses.csv")
<<<<<<< HEAD
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(stringr)
knitr::opts_chunk$set(echo = TRUE)
survey <- read_csv("../src/data/survey_responses_latest.csv")
survey <- read_csv("../src/data/survey_responses.csv")
getwd()
survey <- read_csv("../data/survey_responses.csv")
survey <- read_csv("../../data/survey_responses.csv")
survey <- read_csv("../../data/survey_responses.csv")
kable(head(survey))
survey_analysis <- survey %>%
select(-c(1,2))
colnames(survey_analysis) <- c("academic","codingexp","lovecoding","firstprog","preferprog","dstask","noofprog")
kable(head(survey_analysis))
survey_analysis %>% group_by(preferprog)%>%
summarize(count=n()) %>%
kable()
#survey_analysis$academic <- str_replace(tolower(survey_analysis$academic),c(".*econ.*",".*fin.*",".*business.*"),"Business")
#survey_analysis$academic <- str_replace(tolower(survey_analysis$academic),c(".*econ.*",".*fin.*",".*business.*"),"Business")
#?str_replace
#survey_analysis$academic <- str_replace(survey_analysis$academic,"Mathematics / Statistics","Math & Stats")
survey_analysis$academic <- str_replace(survey_analysis$academic,"Computer Science / Computer Engineering","computer")
survey_analysis$academic <- str_replace(tolower(survey_analysis$academic),".*econ.*","business")
survey_analysis$academic <- str_replace(tolower(survey_analysis$academic),".*busi.*","business")
survey_analysis$academic <- str_replace(tolower(survey_analysis$academic),".*eng.*","engineering")
# Creating a vector, putting all the fields to others
survey_clean_1 <- c("business","computer","engineering","mathematics / statistics")
#interact_clean$name[!(interact_clean$name %in% interact_clean_1)] <- "other"
survey_analysis$academic[!(survey_analysis$academic%in% survey_clean_1)] <- "other"
# Summary
survey_analysis_count<- survey_analysis %>%
group_by(academic) %>%
summarise(count=n()) %>%
View()
survey_analysis %>%
ggplot(aes(academic))+geom_bar(fill="red",position = "dodge")+
labs(title="Bar Chart",x="Academic Background",y="Count") +
theme_bw()
survey_analysis %>%
ggplot() +
geom_bar(aes(x = dstask,fill = dstask)) +
facet_wrap(~academic)
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~academic)
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~dstask)+theme_bw()+
scale_fill_discrete(name = "Choice of languge")+
ggtitle("Data Science Task ")+xlab("Choice of language") + ylab("Count")+
theme(plot.title = element_text(hjust = 0.5,face="bold",size=16))
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~codingexp)+theme_bw()+
scale_fill_discrete(name = "Choice of languge")+
ggtitle("Data Science Task ")+xlab("Choice of language") + ylab("Count")+
theme(plot.title = element_text(hjust = 0.5,face="bold",size=16))
survey_analysis %>%
ggplot() +
geom_bar(aes(x = preferprog,fill = preferprog)) +
facet_wrap(~lovecoding)+theme_bw()+
scale_fill_discrete(name = "Choice of languge")+
ggtitle("Data Science Task ")+xlab("Choice of language") + ylab("Count")+
theme(plot.title = element_text(hjust = 0.5,face="bold",size=16))
=======
<<<<<<< HEAD
getwd()
=======
devtools::build_vignettes()
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages(library(tidyverse))
responses <- read.csv(file = "../docs/survey_results_clean.csv")
suppressPackageStartupMessages(library(tidyverse))
responses <- read.csv(file = "docs/survey_results_clean.csv")
reponses
responses
glm(preference ~ task + first , data = responses)
glm(rep(1, nrow(responses)) ~ task + first , data = responses)
responses %>% select(preference, task)
names(responses)
responses %>% select(preference, task, "background")
names(responses)
responses
names(responses)
responses %>% select(preference, task, "background", "active")
data <- responses %>% select(preference, task, "background", "active") %>% mutate(response = if_else(preference == "Python", 1, 0))
data
data <- responses %>% select(preference, task, "background", "active") %>% mutate(binary = if_else(preference == "Python", 1, 0))
glm(binary ~ task + first , data = data)
data <- responses %>% select(preference, task, "background", "active", first) %>% mutate(binary = if_else(preference == "Python", 1, 0))
glm(binary ~ task + first , data = data)
mod <- glm(binary ~ task + first , data = data)
summary(mod)
mod <- glm(binary ~ task data = data)
mod <- glm(binary ~ task, data = data)
summary(mod)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
library(tidyverse)
theme_set(theme_bw())
#Reading in all the CrazyEgg datasets
interact <- read_csv("data/CrazyEgg/Homepage Version 1 - Interact, 5-29-2013/Element list Homepage Version 1 - Interact, 5-29-2013.csv")
connect <- read_csv("data/CrazyEgg/Homepage Version 2 - Connect, 5-29-2013/Element list Homepage Version 2 - Connect, 5-29-2013.csv")
learn <- read_csv("data/CrazyEgg/Homepage Version 3 - Learn, 5-29-2013/Element list Homepage Version 3 - Learn, 5-29-2013.csv")
help <- read_csv("data/CrazyEgg/Homepage Version 4 - Help, 5-29-2013/Element list Homepage Version 4 - Help, 5-29-2013.csv")
services <- read_csv("data/CrazyEgg/Homepage Version 5 - Services, 5-29-2013/Element list Homepage Version 5 - Services, 5-29-2013.csv")
cleaning <- function(df_raw, variant, rate = TRUE){
#The function can be used to extract the number of clicks or the CTR.
#Extracting the total number of clicks
df <- df_raw %>% filter(Name != 'Montana State University - Home')
total_clicks <- df$`No. clicks` %>% sum()
#Extracting the clicks on find
find <- df %>% filter( Name %in% c("FIND", "lib.montana.edu/find/"))
find_clicks <- find$`No. clicks` %>% sum()
#Extracting the click on request
request <- df %>% filter( Name %in% c("REQUEST", "lib.montana.edu/request/"))
request_clicks <- request$`No. clicks` %>% sum()
#Extracting the clicks on the interact/other variants
interact <- df %>% filter( Name %in% c(variant, "lib.montana.edu/interact/"))
interact_clicks <- interact$`No. clicks` %>% sum()
#Extracting the clicks on search
search <- df %>% filter( Name %in% c("Search", "lib.montana.edu/search/", "s.q"), `Tag name` != "form")
search_clicks <- search$`No. clicks` %>% sum()
#Extracting all other clicks
other_clicks <- total_clicks - find_clicks - request_clicks - interact_clicks - search_clicks
if(!rate){
#Return number of clicks
ctr <- c(find_clicks, request_clicks, interact_clicks, search_clicks, other_clicks)
names(ctr) <- c("FIND", "REQUEST", variant, "SEARCH", "Other")
return(ctr)
}
#Return CTR
find_rate <- find_clicks/total_clicks
request_rate <- request_clicks/total_clicks
interact_rate <- interact_clicks/total_clicks
search_rate <- search_clicks/total_clicks
other_rate <- other_clicks/total_clicks
ctr <- c(find_rate, request_rate, interact_rate, search_rate, other_rate)*100
names(ctr) <- c("FIND", "REQUEST", variant, "SEARCH", "Other")
return(ctr)
}
#Obtain the CTR for each of the 5 dataframes.
interact_ctr <- cleaning(interact, "INTERACT")
connect_ctr <- cleaning(connect, "CONNECT")
learn_ctr <- cleaning(learn, "LEARN")
help_ctr <- cleaning(help, "HELP")
services_ctr <- cleaning(services, "SERVICES")
#Bar plot of CTR for each variats
barplot(c(services_ctr[3], connect_ctr[3], interact_ctr[3], help_ctr[3], learn_ctr[3]),
main = "Click-through Rates - Homepage",
ylim = c(0,6), ylab = "Click-through Rates",
xlab = "Experiment Variables")
#Extracting the number of clicks
interact_number <- cleaning(interact, "INTERACT", rate = FALSE)
connect_number <- cleaning(connect, "CONNECT", rate = FALSE)
learn_number <- cleaning(learn, "LEARN", rate = FALSE)
help_number <- cleaning(help, "HELP", rate = FALSE)
services_number <- cleaning(services, "SERVICES", rate = FALSE)
# Calculate the confidence interval for the clicks of all the 5 different variants.
conf <- epitools::binom.exact(services_number[3], sum(services_number))
conf <- rbind(conf,epitools::binom.exact(interact_number[3], sum(interact_number)))
conf <- rbind(conf,epitools::binom.exact(learn_number[3], sum(learn_number)))
conf <- rbind(conf,epitools::binom.exact(help_number[3], sum(help_number)))
conf <- rbind(conf,epitools::binom.exact(connect_number[3], sum(connect_number)))
conf$name <- row.names(conf)
#https://stackoverflow.com/questions/14069629/plotting-confidence-intervals?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
#Plot of the confidence interval for all the 5 variants.
conf %>% ggplot() + geom_point(aes(x = name, proportion),size = 3) + geom_errorbar(aes(x = name, ymin = lower, ymax = upper)) + labs(title = "Confidence intervals for CTR", x = "Names", y = "Proportions")
pie.plot <- function(df_raw, variant) {
#Function to plot the pie chart for CTR
ctr <- cleaning(df_raw, variant)
#Reference: https://www.tutorialspoint.com/r/r_pie_charts.htm
pie(ctr, labels = round(ctr,2),
main = paste("Click-through rates - Homepage,", variant),
col = rainbow(length(ctr)))
legend("topright",names(ctr), cex = 0.8, fill = rainbow(length(ctr)))
}
#Plotting the pie charts
pie.plot(interact, "INTERACT")
pie.plot(connect, "CONNECT")
pie.plot(learn, "LEARN")
pie.plot(help, "HELP")
pie.plot(services, "SERVICES")
click_df <- cbind(interact_ctr[3]/100,sum(interact_number))
click_df <- rbind(click_df,cbind(services_ctr[3]/100,sum(services_number)))
click_df <- rbind(click_df,cbind(connect_ctr[3]/100,sum(connect_number)))
click_df <- rbind(click_df,cbind(learn_ctr[3]/100,sum(learn_number)))
click_df <- rbind(click_df,cbind(help_ctr[3]/100,sum(help_number)))
click_df <- click_df %>% as.data.frame()
names(click_df) <- c("clicks", "total")
click_df <- cbind(click_df,variation = row.names(click_df))
model.data <- data_frame()
set.seed(99)
for (i in 1:length(click_df[,1])){
model.data <- rbind(model.data,cbind(rbinom(n = click_df[i,]$total ,prob = click_df[i,]$clicks, size = 1), as.character(click_df[i,]$variation)))
}
colnames(model.data) <- c("click", "name")
model <- glm(click ~ name, family = binomial(link = 'logit'), data = model.data)
summary(model)
p.vals <- summary(model)$coef[,4]
p.adjust(p.vals ,method = "BH") < 0.05
pwr::pwr.anova.test(k = 5, power = 0.8, f = 0.4)
#power.prop.test(power = 0.8, p1 = 0.02847709 , p2 = 0.02821317)
#power.prop.test(power = 0.8, p1 = 0.02847709 , p2 = 0.03906742)
library(rjags)
click_count <- data_frame()
click_count <- cbind(interact_number[3],sum(interact_number))
click_count <- rbind(click_count,cbind(services_number[3],sum(services_number)))
click_count <- rbind(click_count,cbind(connect_number[3],sum(connect_number)))
click_count <- rbind(click_count,cbind(learn_number[3],sum(learn_number)))
click_count <- rbind(click_count,cbind(help_number[3],sum(help_number)))
click_count <- click_count %>% as.data.frame()
names(click_count) <- c("clicks", "total")
click_count <- cbind(click_count,variation = row.names(click_count))
#Computing the posterior distribution using jags
my_model <- "
model{
for (i in 1:N){
#Prior distribution
theta[i] ~ dbeta(1, 1)
#Statistic model
ll[i] ~ dbinom(theta[i], n[i])
}
}
"
mod <- jags.model(textConnection(my_model), data=list(ll = c(click_count$clicks), n = c(click_count$total), N = 5))
jags_coin <- coda.samples(mod, variable.names=c("theta"), n.iter=10000)
plot(jags_coin)
beta.est <- summary(jags_coin)$statistics[,"Mean"][1:5]
beta.int <- t(apply(as.matrix(jags_coin), 2, quantile, prob=c(.025,.975)))
plot(1:5, beta.est, pch=20, ylim=c(0,0.07),ylab=expression(beta),
xlab="", main="95% ET credible intervals")
for (i in 1:5) {
points(rep(i,2), beta.int[i,], type="l",
col=c("black","red")[1+as.numeric((beta.int[i,1]*beta.int[i,2])>0)])
}
#The order of the confidence intervals are as given below
row.names(click_count)
model.data
model <- glm(click ~ name, family = binomial(link = 'logit'), data = model.data)
data
data <- responses %>% mutate(binary = if_else(preference == "Python", 1, 0))%>% select(preference, binary, task, "background", "active", first)
data
mod <- glm(binary ~ task, data = data)
summary(mod)
summary(model)
mod <- glm(binary ~ task + first, data = data)
summary(mod)
mod <- glm(binary ~ task + first + background, data = data)
summary(mod)
responses
data <- responses %>% mutate(binary = if_else(preference == "Python", 1, 0))%>% select(preference, binary, task, "background", "active", first, attitude)
mod <- glm(binary ~ task + first + background + attitude, data = data)
summary(mod)
model <- glm(binary ~ task + first + background + attitude, data = data)
summary(mod)
p.vals <- summary(model)$coef[,4]
p.adjust(p.vals ,method = "BH") < 0.05
model <- glm(binary ~ task + first + background + attitude, data = data)
summary(mod)
p.vals <- summary(model)$coef[,4]
p.adjust(p.vals ,method = "BH") < 0.05
p.adjust(p.vals ,method = "BH") < 0.05
model <- glm(binary ~ task + first, data = data)
summary(mod)
p.vals <- summary(model)$coef[,4]
p.adjust(p.vals ,method = "BH") < 0.05
model <- glm(binary ~ task + first, data = data)
summary(mod)
names(responses)
data <- responses %>% mutate(binary = if_else(preference == "Python", 1, 0))%>% select(preference, binary, task, "background", "active", first, attitude)
data
mod <- glm(binary ~ task, data = data)
summary(mod)
model <- glm(binary ~ task + first, data = data)
summary(mod)
summary(model)
model <- glm(binary ~ task + attitude, data = data)
summary(model)
model <- glm(binary ~ task + attitude + first + background, data = data)
summary(model)
knitr::opts_chunk$set(echo = FALSE)
source('get_plots.R')
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(cowplot))
suppressPackageStartupMessages(library(ggalluvial))
responses <- read.csv(file = "../docs/survey_results_clean.csv")
plot_title <- c("Academic Background", "Years of Coding Experience", "User Who Love/Enjoy Coding", "First Programming Language",
"R or Python", "Preferred Data Science Task", "Number of Languages Actively Being Used")
plot_colors <- c("red", "blue4")
#R or Python !!
pie_plot(responses[,c(5,5)], 5, plot_title, colnames(responses[,5]))
#Preferred Data Science Task
pie_plot(responses[,c(6,5)], 6, plot_title, colnames(responses[,6]))
responses %>%
ggplot() +
geom_bar(aes(x = preference,fill = preference), alpha = 0.7) +
facet_wrap(~task) + theme_bw() +
scale_fill_manual(name = "Choice of languge", values = plot_colors) +
ggtitle("Facet Plot for Preferred Data Science Task") + xlab("Choice of language") + ylab("Count") +
theme(plot.title = element_text(hjust = 0.5,size=16))
#Academic Background
#proportion_plot(responses[,c(1,5)], 1, plot_title, colnames(responses[,1]))
bar_plot(responses[,c(1,5)], 1, plot_title, colnames(responses[,1]))
grouped_df <- responses %>% group_by(background, preference, task) %>% summarise(count = n())
ggplot(grouped_df,
aes(weight = count,
axis1 = task, axis2 = background, axis3 = preference)) +
geom_alluvium(aes(fill = task),
width = 0) +
guides(fill = FALSE) +
geom_stratum(reverse = TRUE, alpha = 0.6) +
geom_text(stat = "stratum", label.strata = TRUE, reverse = TRUE, size = 3) +
scale_x_continuous(breaks = 1:3, labels = c("Preferred Task", "Background", "Language")) +
ggtitle("Alluvial Plot for Language Preference") + theme(axis.text.y = element_blank()) + theme_void()+
theme(plot.title = element_text(hjust = 0.5,size=16))
#Years of Coding Experience
pie_plot(responses[,c(2,5)], 2, plot_title, colnames(responses[,2]))
responses %>%
ggplot() +
geom_bar(aes(x = preference,fill = preference), alpha = 0.7) +
facet_wrap(~experience) + theme_bw() +
scale_fill_manual(name = "Choice of languge", values = plot_colors) +
ggtitle("Facet plot for Years of Coding Experience") + xlab("Years of Coding Experience") + ylab("Count") +
theme(plot.title = element_text(hjust = 0.5, size=16))
#Attitude Towards
pie_plot(responses[,c(3,5)], 3, plot_title, colnames(responses[,3]))
responses %>%
ggplot() +
geom_bar(aes(x = preference, fill = preference), alpha = 0.7) +
facet_wrap(~attitude) + theme_bw() +
scale_fill_manual(name = "Choice of languge", values = plot_colors) +
ggtitle("Facet Plot for User Who Love/Enjoy Coding") + xlab("Choice of language") + ylab("Count") +
theme(plot.title = element_text(hjust = 0.5, size=16))
#First Programming Language
#proportion_plot(responses[,c(4,5)], 4, plot_title, colnames(responses[,4]))
bar_plot(responses[,c(4,5)], 4, plot_title, colnames(responses[,4]), flip = FALSE)
#Number of Languages Actively Being Used
#proportion_plot(responses[,c(6,5)], 6, plot_title, colnames(responses[,7]))
bar_plot(responses[,c(7,5)], 7, plot_title, colnames(responses[,7]), flip = FALSE)
responses %>% colnames()
mod <- glm(binary ~ task + background + experience + attitude + first + active, data = responses)
data_all <- responses %>% mutate(binary = if_else(preference == "Python", 1, 0))
mod <- glm(binary ~ task + background + experience + attitude + first + active, data = data_all)
summary(mod)
mod <- glm(binary ~ task + first + background + experience + attitude + active, data = data_all)
summary(mod)
mod <- glm(binary ~ task + first + background + experience + attitude, data = data_all)
summary(mod)
mod <- glm(binary ~ task + first + background, data = data_all)
summary(mod)
mod <- glm(binary ~ task + background + experience + attitude + first + active, data = data_all)
summary(mod)
model <- glm(binary ~ task + first, data = data)
summary(model)
relevel(data$first,ref="Matlab")
data_relevel <- data
data_relevel$first <-relevel(data$first,ref="Matlab")
model <- glm(binary ~ task + first, data = data)
summary(model)
model <- glm(binary ~ task + first, data = data_relevel)
summary(model)
data_relevel <- data
ata_relevel$task
data_relevel$task
data_relevel$task <-relevel(data$task,ref="Machine Learning")
model <- glm(binary ~ task + first, data = data)
summary(model)
model <- glm(binary ~ task + first, data = data_relevel)
summary(model)
data_relevel <- data
data_relevel <- data
data_relevel$task <-relevel(data$task,ref="Machine Learning")
data_relevel$first <-relevel(data$first,ref="R")
model <- glm(binary ~ task + first, data = data)
summary(model)
model <- glm(binary ~ task + first, data = data_relevel)
summary(model)
responses %>% colnames()
#All the data with
data <- responses %>% mutate(binary = if_else(preference == "Python", 1, 0))
responses %>% colnames()
mod <- glm(binary ~ task + background + experience + attitude + first + active, data = data)
summary(mod)
mod <- glm(binary ~ task + first + background, data = data_all)
summary(mod)
model <- glm(binary ~ task + attitude + first + background, data = data)
summary(model)
#All the data with
data <- responses %>% mutate(binary = if_else(preference == "Python", 1, 0))
responses %>% colnames()
mod <- glm(binary ~ task + background + experience + attitude + first + active, data = data)
summary(mod)
#Model with only first language or background
mod <- glm(binary ~ task + first + background, data = data_all)
summary(mod)
#Releveling the reference task from Data Viz -> Machine Learning
#Releveling the reference first language from C -> R
data_relevel <- data
data_relevel$task <-relevel(data$task,ref="Machine Learning")
data_relevel$first <-relevel(data$first,ref="R")
model <- glm(binary ~ task + first, data = data_relevel)
summary(model)
#Binary encoding the response variable. Python -> 1; R -> 0
data <- responses %>% mutate(binary = if_else(preference == "Python", 1, 0))
#Fitting a GLM without any confounding variables.
mod <- glm(binary ~ task, data = data)
summary(mod)
model <- glm(binary ~ task + first, data = data)
summary(model)
#Adjusting for p-values.(Not required anymore after chat with Tiffany)
#p.vals <- summary(model)$coef[,4]
#p.adjust(p.vals ,method = "BH") < 0.05
>>>>>>> upstream/master
>>>>>>> upstream/master
